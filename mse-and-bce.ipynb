{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mean Squared Error","metadata":{}},{"cell_type":"markdown","source":"## MSE Calculation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nloss_object = nn.MSELoss()\n\nbatch_size = 32\npredictions = torch.randn(batch_size, 1)\nlabels = torch.randn(batch_size, 1)\n\nmse = loss_object(predictions, labels)\nprint(\"MSE(torch): \", mse.item())\n\nmse_manual = torch.mean(torch.pow(labels - predictions, 2))\n\nprint(\"MSE(manual): \", mse_manual.item())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T15:54:27.163559Z","iopub.execute_input":"2022-06-20T15:54:27.164399Z","iopub.status.idle":"2022-06-20T15:54:27.173844Z","shell.execute_reply.started":"2022-06-20T15:54:27.164358Z","shell.execute_reply":"2022-06-20T15:54:27.173144Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"MSE(torch):  1.4898978471755981\nMSE(manual):  1.4898978471755981\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## MSE with Model/Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_feature = 100, 5\nbatch_size = 32\n\nX = torch.randn(N, n_feature)\nY = torch.randn(N, 1)\n\n\n# 하나의 Dense Layer와 MSE를 계산하는 모델 설계\nclass Dense(torch.nn.Module):\n    def __init__(self):\n        super(Dense, self).__init__()\n        self.layer = nn.Linear(5, 1)\n        self.mse = nn.MSELoss()\n        \n    def forward(self, x, y):\n        x = self.layer(x)\n        x = self.mse(x, y)\n        return x\n\n# Dataset 클래스를 상속받아 커스텀 데이터셋 클래스 생성\nclass custom_dataset(Dataset):\n    def __init__(self, x_data, y_data):\n        self.x_data = torch.FloatTensor(x_data)\n        self.y_data = torch.FloatTensor(y_data)\n        self.len = self.y_data.shape[0]\n        \n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n\n    def __len__(self):\n        return self.len\n    \n# 인스터스(데이터) 생성\ntrain_data = custom_dataset(X, Y)\n\n# 만들어진 데이터가 배치형태로 만들어줘야하니까 DataLoader에다가 넣어줌\ntrain_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n\nmodel = Dense()\n\n\nfor x, y in train_loader:\n    #print(x.shape, y.shape)\n    loss = model(x, y)\n    print(loss.detach().numpy())\n\n#mse_manual = torch.mean(torch.pow(labels - predictions, 2))\n\n#print(\"MSE(manual): \", mse_manual.item())\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T16:10:43.641639Z","iopub.execute_input":"2022-06-20T16:10:43.642047Z","iopub.status.idle":"2022-06-20T16:10:43.670359Z","shell.execute_reply.started":"2022-06-20T16:10:43.642016Z","shell.execute_reply":"2022-06-20T16:10:43.669223Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"1.4717449\n1.7970073\n1.3212402\n0.58484834\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Binary Cross Entropy","metadata":{}},{"cell_type":"markdown","source":"## BCE Calculation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nbatch_size = 32\nn_class = 2\n\npredictions = torch.rand((batch_size, 1))\n\n# randint's 2nd arg -> One above the highest integer to be drawn from the distribution.\nlabels = torch.randint(0, n_class , (batch_size, 1))\n\nloss_object = nn.BCELoss()\nlabels = labels.type(torch.FloatTensor)\nloss = loss_object(predictions, labels)\n\n# BCE: -[ylog(y^) + (1 - y)log(1 - y^)]\nbce_manual = -(labels * torch.log(predictions) + (1 - labels) * torch.log(1 - predictions))\nbce_manual = torch.mean(bce_manual)\n\nprint(\"BCE(Torch): \", loss.detach().numpy())\nprint(\"BCE(Manual): \", bce_manual.detach().numpy())\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T16:52:22.774214Z","iopub.execute_input":"2022-06-20T16:52:22.775195Z","iopub.status.idle":"2022-06-20T16:52:22.787256Z","shell.execute_reply.started":"2022-06-20T16:52:22.775129Z","shell.execute_reply":"2022-06-20T16:52:22.786379Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"BCE(Torch):  1.0998785\nBCE(Manual):  1.0998785\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## BCE with Model/Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_features = 100, 5 \n\n# Binary Classification을 위한 예제 Dataset 생성\ntorch_weights = torch.tensor([1, 2, 3, 4, 5], dtype = torch.float32)\ntorch_bias = torch.tensor([10], dtype = torch.float32)\n\nX = torch.randn(N, n_features)\n#print(X)\nY = torch.sum(torch_weights * X, 1) + torch_bias\n#print(Y)\nY = (Y > 5).type(torch.int32)\nY = Y.type(torch.FloatTensor)\n# 추후에 진행될 BCE loss 연산을 위해 2차원 데이터로 만들어준다.\nY = Y.unsqueeze(1) \n\n\n# 하나의 Dense Layer와 MSE를 계산하는 모델 설계\nclass Dense(torch.nn.Module):\n    def __init__(self):\n        super(Dense, self).__init__()\n        self.layer = nn.Linear(5, 1)\n        self.sigmoid = nn.Sigmoid()\n        \n        \n    def forward(self, x):\n        x = self.layer(x)\n        x = self.sigmoid(x)\n        return x\n    \nmodel = Dense()\nloss_object = nn.BCELoss()\n\n\n# Dataset 클래스를 상속받아 커스텀 데이터셋 클래스 생성\nclass custom_dataset(Dataset):\n    def __init__(self, x_data, y_data):\n        self.x_data = torch.FloatTensor(x_data)\n        self.y_data = torch.FloatTensor(y_data)\n        self.len = self.y_data.shape[0]\n        \n    def __getitem__(self, index):\n        return self.x_data[index], self.y_data[index]\n\n    def __len__(self):\n        return self.len\n    \n    \n# 인스터스(데이터) 생성\ntrain_data = custom_dataset(X, Y)\n\n# 만들어진 데이터가 배치형태로 만들어줘야하니까 DataLoader에다가 넣어줌\ntrain_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n\n\nfor x, y in train_loader:\n    predictions = model(x)\n    loss = loss_object(predictions, y)\n    print(loss.item())\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-06-20T17:06:30.464795Z","iopub.execute_input":"2022-06-20T17:06:30.465189Z","iopub.status.idle":"2022-06-20T17:06:30.484630Z","shell.execute_reply.started":"2022-06-20T17:06:30.465157Z","shell.execute_reply":"2022-06-20T17:06:30.483518Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"0.7864617705345154\n0.7628585696220398\n0.8226035833358765\n0.8106143474578857\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}