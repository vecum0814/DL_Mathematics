{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Conv Layers","metadata":{}},{"cell_type":"markdown","source":"## Shapes of Conv Layers","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_H, n_W, n_C = 1, 28, 28, 5\nn_filter = 10\nf_size = 3\n\nimages = torch.rand(N, n_C, n_H, n_W,)\n \nclass Conv(torch.nn.Module):\n    def __init__(self):\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(n_C, n_filter, f_size) # # 합성곱 연산 (입력 채널수 1, 출력 채널수 1, 필터크기 28x28 , stride=1(defualt))\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return x\n    \nmodel = Conv()\n\ny = model(images)\nw = list(model.parameters()) # get the values of weight, bias\n\nweight = w[0]\nbias = w[1]\n\nprint(images.shape)\nprint(weight.shape)\nprint(bias.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:06:04.957196Z","iopub.execute_input":"2022-06-30T05:06:04.957535Z","iopub.status.idle":"2022-06-30T05:06:04.969567Z","shell.execute_reply.started":"2022-06-30T05:06:04.957511Z","shell.execute_reply":"2022-06-30T05:06:04.968437Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"torch.Size([1, 5, 28, 28])\ntorch.Size([10, 5, 3, 3])\ntorch.Size([10])\ntorch.Size([1, 10, 26, 26])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Correlation Calculation","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_H, n_W, n_C = 1, 5, 5, 1\nn_filter = 1\nf_size = 3\n\nimages = torch.rand(N, n_C, n_H, n_W,)\n \nclass Conv(torch.nn.Module):\n    def __init__(self):\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(n_C, n_filter, f_size) # # 합성곱 연산 (입력 채널수 1, 출력 채널수 1, 필터크기 28x28 , stride=1(defualt))\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return x\n    \nmodel = Conv()\n\ny = model(images)\nprint(\"Y(Torch): \", y.detach().numpy().squeeze())\n\nw = list(model.parameters()) # get the values of weight, bias\n\nweight = w[0]\nbias = w[1]\n\nimages = images.numpy().squeeze()\nweight = weight.squeeze()\nweight = weight.detach().numpy()\n\nprint(images.shape)\nprint(weight.shape)\n#print(bias.shape)\n\ny_manual = np.zeros(shape = (n_H - f_size + 1, n_W - f_size + 1))\nfor i in range(n_H - f_size + 1):\n    for j in range(n_W - f_size + 1):\n        window = images[i : i + f_size, j : j + f_size]\n        y_manual[i, j] = np.sum(window * weight) + bias\n        \nprint(\"Y(Manual): \\n\", y_manual)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:09:37.585845Z","iopub.execute_input":"2022-06-30T05:09:37.586175Z","iopub.status.idle":"2022-06-30T05:09:37.602335Z","shell.execute_reply.started":"2022-06-30T05:09:37.586151Z","shell.execute_reply":"2022-06-30T05:09:37.601437Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Y(Torch):  [[0.5396451  0.13605362 0.16865982]\n [0.26625252 0.30295843 0.23418044]\n [0.13633503 0.257427   0.23276612]]\n(5, 5)\n(3, 3)\nY(Manual): \n [[0.53964508 0.13605362 0.16865985]\n [0.26625252 0.30295852 0.23418045]\n [0.13633502 0.25742698 0.23276612]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Correlation with n-channel","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_H, n_W, n_C = 1, 5, 5, 3\nn_filter = 1\nf_size = 3\n\nimages = torch.rand(N, n_C, n_H, n_W,)\n \nclass Conv(torch.nn.Module):\n    def __init__(self):\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(n_C, n_filter, f_size) # # 합성곱 연산 (입력 채널수 1, 출력 채널수 1, 필터크기 28x28 , stride=1(defualt))\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return x\n    \nmodel = Conv()\n\ny = model(images)\nprint(\"Y(Torch): \", y.detach().numpy().squeeze())\n\nw = list(model.parameters()) # get the values of weight, bias\n\nweight = w[0]\nbias = w[1]\n\nimages = images.numpy().squeeze()\nweight = weight.squeeze()\nweight = weight.detach().numpy()\n\n#print(images.shape)\n#print(weight.shape)\n#print(bias.shape)\n\ny_manual = np.zeros(shape = (n_H - f_size + 1, n_W - f_size + 1))\nfor i in range(n_H - f_size + 1):\n    for j in range(n_W - f_size + 1):\n        window = images[:, i : i + f_size, j : j + f_size]\n        #print(window.shape)\n        y_manual[i, j] = np.sum(window * weight) + bias\n        \nprint(\"Y(Manual): \\n\", y_manual)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T05:11:43.809171Z","iopub.execute_input":"2022-06-30T05:11:43.809539Z","iopub.status.idle":"2022-06-30T05:11:43.826279Z","shell.execute_reply.started":"2022-06-30T05:11:43.809509Z","shell.execute_reply":"2022-06-30T05:11:43.825396Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Y(Torch):  [[0.5439341  0.49860427 0.34091172]\n [0.5010702  0.49791315 0.6776478 ]\n [0.46009868 0.13545343 0.18529502]]\nY(Manual): \n [[0.54393411 0.49860421 0.34091175]\n [0.5010702  0.49791315 0.67764777]\n [0.46009874 0.13545345 0.18529497]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}