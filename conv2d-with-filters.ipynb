{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Conv Layer with Filters","metadata":{}},{"cell_type":"markdown","source":"## Shapes with Filters","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_H, n_W, n_C = 1, 28, 28, 3\nn_filter = 5\nk_size = 3\n\nimages = torch.rand(N, n_C, n_H, n_W,)\n \nclass Conv(torch.nn.Module):\n    def __init__(self):\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(n_C, n_filter, k_size) # # 합성곱 연산 (입력 채널수 , 출력 채널수, 필터크기, stride=1(defualt))\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return x\n    \nmodel = Conv()\n\nprint(\"Input Image: {}\".format(images.shape))\n\ny = model(images)\nw = list(model.parameters()) # get the values of weight, bias\n\nweight = w[0]\nbias = w[1]\n\nprint(\"W/B: {} / {}\".format(weight.shape, bias.shape))\nprint(\"Output Image: {}\".format(y.shape))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-01T04:34:43.489709Z","iopub.execute_input":"2022-07-01T04:34:43.490135Z","iopub.status.idle":"2022-07-01T04:34:43.504526Z","shell.execute_reply.started":"2022-07-01T04:34:43.490099Z","shell.execute_reply":"2022-07-01T04:34:43.50334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Computations with Filters","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_H, n_W, n_C = 1, 5, 5, 3\nn_filter = 3\nk_size = 4\n\nimages = torch.rand(N, n_C, n_H, n_W,)\n \nclass Conv(torch.nn.Module):\n    def __init__(self):\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(n_C, n_filter, k_size) # # 합성곱 연산 (입력 채널수 , 출력 채널수, 필터크기, stride=1(defualt))\n        \n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n# Forward Propagation (PyTorch)\nmodel = Conv()\ny = model(images)\ny = y.detach().numpy().squeeze()\n\n#print(y.shape)\nprint(\"Output(PyTorch): \\n\", y)\n\n\n# Forward Propagation (Manual)\nimages = images.numpy().squeeze()\n#print(images.shape)\n\nw = list(model.parameters()) # get the values of weight, bias\n\nweight = w[0].detach().numpy()\nbias = w[1].detach().numpy()\n\n#print(weight.shape, bias.shape)\n\ny_manual = np.zeros(shape = (n_filter, n_H - k_size + 1, n_W - k_size + 1))\nfor c in range(n_filter):\n    c_W = weight[c, : , :, :] # (3 [n_filter], 3 [n_C], 4, 4)\n    c_b = bias[c]\n    \n    #print(c_W.shape, c_b.shape) (3 [n_filter], 3 [n_C], 4, 4)\n    for h in range(n_H - k_size + 1):\n        for w in range(n_W - k_size + 1):\n            window = images[:, h : h + k_size, w : w + k_size]\n            #print(window.shape, c_W.shape)\n            conv = np.sum(window * c_W) + c_b\n            \n            y_manual[c, h, w] = conv\n            \nprint(\"Output(Manual): \\n\", y_manual)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:43:49.021271Z","iopub.execute_input":"2022-07-04T09:43:49.021708Z","iopub.status.idle":"2022-07-04T09:43:49.043711Z","shell.execute_reply.started":"2022-07-04T09:43:49.021673Z","shell.execute_reply":"2022-07-04T09:43:49.042287Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Output(PyTorch): \n [[[ 0.0365082   0.2748231 ]\n  [-0.18641067 -0.04044719]]\n\n [[ 0.0192028  -0.03857959]\n  [ 0.16839142  0.15484396]]\n\n [[-0.3403398  -0.2549873 ]\n  [-0.16018073 -0.01625764]]]\nOutput(Manual): \n [[[ 0.03650818  0.2748231 ]\n  [-0.18641062 -0.04044713]]\n\n [[ 0.01920291 -0.03857952]\n  [ 0.16839141  0.15484402]]\n\n [[-0.34033984 -0.25498742]\n  [-0.16018072 -0.01625761]]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Conv Layers with Activation Functions","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN, n_H, n_W, n_C = 1, 5, 5, 3\nn_filter = 3\nk_size = 4\n\nimages = torch.rand(N, n_C, n_H, n_W,)\n \nclass Conv(torch.nn.Module):\n    def __init__(self):\n        super(Conv, self).__init__()\n        self.conv = nn.Conv2d(n_C, n_filter, k_size) # # 합성곱 연산 (입력 채널수 , 출력 채널수, 필터크기, stride=1(defualt))\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.sigmoid(x)\n        return x\n\n# Forward Propagation (PyTorch)\nmodel = Conv()\ny = model(images)\ny = y.detach().numpy().squeeze()\n\n#print(y.shape)\nprint(\"Output(PyTorch): \\n\", y)\n\n\n# Forward Propagation (Manual)\nimages = images.numpy().squeeze()\n#print(images.shape)\n\nw = list(model.parameters()) # get the values of weight, bias\n\nweight = w[0].detach().numpy()\nbias = w[1].detach().numpy()\n\n#print(weight.shape, bias.shape)\n\ny_manual = np.zeros(shape = (n_filter, n_H - k_size + 1, n_W - k_size + 1))\nfor c in range(n_filter):\n    c_W = weight[c, : , :, :] # (3 [n_filter], 3 [n_C], 4, 4)\n    c_b = bias[c]\n    \n    #print(c_W.shape, c_b.shape) (3 [n_filter], 3 [n_C], 4, 4)\n    for h in range(n_H - k_size + 1):\n        for w in range(n_W - k_size + 1):\n            window = images[:, h : h + k_size, w : w + k_size]\n            #print(window.shape, c_W.shape)\n            conv = np.sum(window * c_W) + c_b\n            conv = 1 / (1 + np.exp(-conv))\n            \n            y_manual[c, h, w] = conv\n            \nprint(\"Output(Manual): \\n\", y_manual)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:47:08.509308Z","iopub.execute_input":"2022-07-04T09:47:08.509756Z","iopub.status.idle":"2022-07-04T09:47:08.528807Z","shell.execute_reply.started":"2022-07-04T09:47:08.509718Z","shell.execute_reply":"2022-07-04T09:47:08.527757Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Output(PyTorch): \n [[[0.35038483 0.32333246]\n  [0.4253918  0.34190372]]\n\n [[0.52321285 0.5765016 ]\n  [0.5975205  0.52960384]]\n\n [[0.54823905 0.52039146]\n  [0.46832937 0.5865657 ]]]\nOutput(Manual): \n [[[0.35038484 0.32333249]\n  [0.4253918  0.34190366]]\n\n [[0.52321281 0.57650161]\n  [0.59752048 0.52960383]]\n\n [[0.54823906 0.52039146]\n  [0.46832937 0.58656572]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}