{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Affine Functions with 1 Feature","metadata":{}},{"cell_type":"markdown","source":"## Affine Function ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn \nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\nimport numpy as np\n\nx = torch.tensor([[10.]]) # input setting\nprint(x.shape)\n\nclass dense(nn.Module): # implementation of an affine function\n    def __init__(self, x):\n        super().__init__()\n        self.out = nn.Linear(1, 1)\n        \n    def forward(self, x):\n        x = self.out(x)\n        return x\n            \n\ny = dense(x) # forward propagation + parameter initialisation.\nw = list(y.parameters()) # get the values of weight, bias\n\n#for p in y.named_parameters():\n#    print(p)\n    \nweight = w[0]\nbias = w[1]\n\nres = torch.matmul(x, weight) + bias\n\nprint('------- Input/Weight/Bias ----')\nprint(\"x: {}\\n{}\\n\".format(x.shape, x.numpy()))\nprint(\"w: {}\\n{}\\n\".format(weight.shape, weight))\nprint(\"b: {}\\n{}\\n\".format(bias.shape, bias))\n\nprint('------Outputs-------')\nprint('result :', res.item())","metadata":{"execution":{"iopub.status.busy":"2022-06-07T11:53:05.705246Z","iopub.execute_input":"2022-06-07T11:53:05.706500Z","iopub.status.idle":"2022-06-07T11:53:05.722646Z","shell.execute_reply.started":"2022-06-07T11:53:05.706450Z","shell.execute_reply":"2022-06-07T11:53:05.721869Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"torch.Size([1, 1])\n------- Input/Weight/Bias ----\nx: torch.Size([1, 1])\n[[10.]]\n\nw: torch.Size([1, 1])\nParameter containing:\ntensor([[0.1549]], requires_grad=True)\n\nb: torch.Size([1])\nParameter containing:\ntensor([0.6797], requires_grad=True)\n\n------Outputs-------\nresult : 2.229147434234619\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Affine Functions with n Features","metadata":{}},{"cell_type":"code","source":"x = torch.randn(1, 10)\nprint(x.shape, '\\n', x)\n\nclass dense(nn.Module): # implementation of an affine function\n    def __init__(self, x):\n        super().__init__()\n        self.out = nn.Linear(x.shape[1], 1)\n        \n    def forward(self, x):\n        x = self.out(x)\n        return x\n    \n    \n    \ny = dense(x) # forward propagation + parameter initialisation.\nw = list(y.parameters()) # get the values of weight, bias\n\n\nweight = w[0]\nprint(weight.shape)\nbias = w[1]\n\ntmp = torch.transpose(weight, 0, 1)\n\n\n\nres = torch.matmul(x, tmp) + bias\n\nprint('------- Input/Weight/Bias ----')\nprint(\"x: {}\\n{}\\n\".format(x.shape, x.numpy()))\nprint(\"w: {}\\n{}\\n\".format(weight.shape, weight))\nprint(\"b: {}\\n{}\\n\".format(bias.shape, bias))\n\nprint('------Outputs-------')\nprint('result :', res.item())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T12:21:46.927554Z","iopub.execute_input":"2022-06-07T12:21:46.927989Z","iopub.status.idle":"2022-06-07T12:21:46.943706Z","shell.execute_reply.started":"2022-06-07T12:21:46.927954Z","shell.execute_reply":"2022-06-07T12:21:46.942286Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"torch.Size([1, 10]) \n tensor([[-0.5020, -1.6458,  0.0757, -2.6537, -0.7118, -1.3015, -1.3694, -1.0865,\n         -0.2114,  0.1399]])\ntorch.Size([1, 10])\n------- Input/Weight/Bias ----\nx: torch.Size([1, 10])\n[[-0.50195575 -1.6458054   0.07569822 -2.6536589  -0.71178687 -1.3014779\n  -1.3693922  -1.0865123  -0.21135391  0.13988337]]\n\nw: torch.Size([1, 10])\nParameter containing:\ntensor([[-0.0126, -0.1751,  0.1606, -0.0448,  0.1597,  0.1657,  0.1396, -0.3060,\n          0.2529, -0.2960]], requires_grad=True)\n\nb: torch.Size([1])\nParameter containing:\ntensor([0.2722], requires_grad=True)\n\n------Outputs-------\nresult : 0.41473355889320374\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}